{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markow Text generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from collections import defaultdict \n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import operator\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoComplete():\n",
    "    def __init__(self):\n",
    "        self.corpus = []\n",
    "        self.n = 0\n",
    "        self.ppFlag = False\n",
    "        self.pbar = False\n",
    "        \n",
    "    def clean_corpus(self):\n",
    "        print(\"\\nCleaning the Corpus !\") if self.ss else None\n",
    "        self.corpus[:] = [item.strip('\"-') for item in self.corpus if bool(re.match('^\\w+|[!.?]',item.strip('\"-')))]\n",
    "        print(f\"Total tokens in corpus : {len(self.corpus)}\") if self.ss else None\n",
    "        \n",
    "    def create_start_word_list(self,top_n):\n",
    "\n",
    "        print(\"\\nCreating start word list !\") if self.ss else None\n",
    "        self.start_word_dict = defaultdict(int)\n",
    "        for i, token in enumerate(self.corpus):\n",
    "            if token in [\".\",\"?\",\"!\"] and i+1<len(self.corpus):\n",
    "                if self.corpus[i+1] not in [\"mrs\",\"ms\",\"mr\",\"eg\",'']:\n",
    "                    self.start_word_dict[self.corpus[i+1]] += 1\n",
    "                    \n",
    "        start_word_list = sorted(self.start_word_dict.items(), \n",
    "                                 key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        self.start_tokens = [word for word,_ in start_word_list]\n",
    "        print(f\"Total unique start words {len(self.start_word_dict)}\") if self.ss else None\n",
    "        print(f\"Selected top {len(self.start_tokens)} start words !\") if self.ss else None\n",
    "        \n",
    "    def create_n_gram_array(self, n):\n",
    "        \"\"\"\n",
    "        Function to create n-gram\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\nGenerating n-grams for n = {n}\") if self.ss else None\n",
    "        n_gram_size = n\n",
    "        n_gram_array = []\n",
    "        for i in tqdm(range(len(self.corpus)-n_gram_size+1), disable = self.pbar):\n",
    "            n_gram_array.append(self.corpus[i:(i+n_gram_size)])\n",
    "        n_gram_array = np.array(n_gram_array)\n",
    "        self.n_gram_array_list.append(n_gram_array)\n",
    "        return self.n_gram_array_list\n",
    "    \n",
    "    def create_n_gram_dict(self, n):\n",
    "        \"\"\"\n",
    "        function to create reference dictionary for n-gram\n",
    "        with n-1 key and nth term as value\n",
    "        \"\"\"\n",
    "        print(f\"\\nGenerating n-gram dictionary for n = {n}\") if self.ss else None\n",
    "        for n_gram in tqdm(self.n_gram_array_list[n-2], disable= self.pbar):\n",
    "            self.n_gram_dict[n][tuple(n_gram[:-1])][n_gram[-1]] += 1\n",
    "    \n",
    "    def create_n_gram(self,corpus,n,top_n):\n",
    "        self.n = n\n",
    "        self.corpus = corpus\n",
    "        self.n_gram_array_list = []\n",
    "        self.n_gram_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(int))) \n",
    "        self.clean_corpus()\n",
    "        self.create_start_word_list(top_n)\n",
    "\n",
    "        print(\"\\nGenerating n-gram and dictionary !\") if self.ss else None\n",
    "            \n",
    "        for i in tqdm(range(2,n+1), disable= self.pbar):\n",
    "            self.create_n_gram_array(i)\n",
    "            self.create_n_gram_dict(i)\n",
    "            \n",
    "    def pre_process_corpus(self,corpus, n_gram_len, top_n=15,show_status=True):\n",
    "        \"\"\"\n",
    "        Function to pre-process the text\n",
    "        Input:\n",
    "            corpus [list]: Source corpus [list of tokens]\n",
    "            n_gram       : maximum limit of n-grams to be created\n",
    "        \"\"\"\n",
    "        self.ss = show_status\n",
    "        self.pbar = not show_status\n",
    "        self.ppFlag = True\n",
    "        self.create_n_gram(corpus, n_gram_len, top_n)\n",
    "        \n",
    "        \n",
    "    def finish_sentence(self, sentence, use_n, deterministic=False, \n",
    "                         max_len=15, stop_at_punc = True):\n",
    "        \"\"\"\n",
    "        Input:-\n",
    "            sentence     : A sentence [list of tokens] that weâ€™re trying to build on\n",
    "            use_n [int]  : The length of n-grams to use for prediction, and\n",
    "            deterministic: Flag indicating whether the process should be deterministic [bool]\n",
    "    \n",
    "        If deterministic is true ; Choose at each step the single most probable next token. \n",
    "                               When two tokens are equally probable, choose the lesser one (according to Python).\n",
    "        If deterministic is false; Draw the next word randomly from the appropriate distribution. Use stupid backoff and no smoothing.\n",
    "    \n",
    "        Output:-\n",
    "            Returns an extended sentence until the first ., ?, or ! is found OR until it has 15 total tokens\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.ppFlag:\n",
    "            raise ValueError(\"N-gram dictionary not generated. Generated the n-gram dictionary first using pre_process_corpus()\")\n",
    "        \n",
    "        if sentence == None:\n",
    "            first_word = np.random.choice(self.start_tokens,1)[0]\n",
    "            self.w_in_sentc = [first_word]\n",
    "        else:\n",
    "            self.w_in_sentc = [w.lower() for w in sentence]\n",
    "            \n",
    "        for i in range(max_len):\n",
    "            suggest_word = self.w_in_sentc[-1]\n",
    "            for i in range(use_n,1,-1):\n",
    "                n_gram_key = tuple(self.w_in_sentc[(-i+1):])\n",
    "\n",
    "                if n_gram_key in self.n_gram_dict[i].keys():\n",
    "                    if deterministic == True:\n",
    "                        most_probab = max(self.n_gram_dict[i][n_gram_key].values())\n",
    "                        opts = []\n",
    "                        for k,v in self.n_gram_dict[i][n_gram_key].items():\n",
    "                            if v == most_probab:\n",
    "                                opts.append(k) \n",
    "                        suggest_word = np.sort(opts)[0]\n",
    "                        break\n",
    "                    else:\n",
    "                        suggest_word = np.random.choice(list(self.n_gram_dict[i][n_gram_key].keys()))\n",
    "                        break\n",
    "            self.w_in_sentc.append(suggest_word)  \n",
    "            \n",
    "            #stop the generation at punctuation\n",
    "            if stop_at_punc and suggest_word in [\".\",\"?\",\"!\"]:\n",
    "                return self.w_in_sentc\n",
    "            \n",
    "        return self.w_in_sentc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Generating text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text using Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case\n",
    "sentence = ['she', 'was', 'not'] \n",
    "n = 3\n",
    "corpus = [w.lower() for w in nltk.corpus.gutenberg.words('austen-sense.txt')]\n",
    "deterministic = True\n",
    "ac = autoComplete()\n",
    "ac.pre_process_corpus(corpus, n_gram_len=3, top_n=100, show_status=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she', 'was', 'not', 'in', 'the', 'world', '.']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.finish_sentence(sentence, 3, max_len= 15, deterministic=True, stop_at_punc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Generating Text\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639a30f9762f4759861cedfb75c511c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#generating corpus with 3-gram (2 words used to predict the third)\n",
    "\n",
    "counter = 0\n",
    "sentence_list= []\n",
    "print(\"\\n Generating Text\")\n",
    "pbar = tqdm(total=150000)\n",
    "max_len = 5\n",
    "while(counter<150000):\n",
    "    gen_sent = ac.finish_sentence(None, 3,max_len=max_len, deterministic=True, stop_at_punc=False)\n",
    "    if len(gen_sent) == max_len+1 and '' not in gen_sent :\n",
    "        pbar.update(1)\n",
    "        sentence_list.append(gen_sent)\n",
    "        counter +=1\n",
    "pbar.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes i am sure i should',\n",
       " 'you will be a very good',\n",
       " 'one of the house and the',\n",
       " 'however i am sure i should',\n",
       " 'margaret and elinor was not in']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list = [\" \".join(sent) for sent in sentence_list]\n",
    "sentence_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated_text_guten.pickle', 'wb') as f:\n",
    "    pickle.dump(sentence_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_gen = open(\"generated_text_guten.pickle\",\"rb\")\n",
    "gen_text = pickle.load(pickle_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating text using Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import re\n",
    "\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57340"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.sents(categories=brown.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb62138f49fa4eb2a62558aab038a8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57339.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326451cfc31748e2bdefaf3427d263c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1161192.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Read and merge all Brown corpus\n",
    "\n",
    "sent_list = brown.sents(categories=brown.categories())\n",
    "corpus_brown = sent_list[0]\n",
    "    \n",
    "for i in tqdm(range(1,len(sent_list))):\n",
    "    corpus_brown = corpus_brown + sent_list[i]\n",
    "\n",
    "corpus_brown = [w.lower() for w in tqdm(corpus_brown)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_brown = autoComplete()\n",
    "ac_brown.pre_process_corpus(corpus_brown,n_gram_len=3,top_n=100,show_status=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['by', 'the', 'time', 'of', 'the', 'united']"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_brown.finish_sentence(None, 3, max_len= 5, deterministic=True, stop_at_punc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Generating Text\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707f49ca8fe14f0a889b42fc91547dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#generating corpus with 3-gram (2 words used to predict the third)\n",
    "\n",
    "counter = 0\n",
    "sentence_list= []\n",
    "print(\"\\n Generating Text\")\n",
    "pbar = tqdm(total=150000)\n",
    "max_len = 5\n",
    "while(counter<150000):\n",
    "    gen_sent = ac_brown.finish_sentence(None, 3,  max_len=max_len, deterministic=True, stop_at_punc=False)\n",
    "    if len(gen_sent) == max_len+1 and '' not in gen_sent :\n",
    "        pbar.update(1)\n",
    "        sentence_list.append(gen_sent)\n",
    "        counter +=1\n",
    "pbar.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"he's a friend of mine .\",\n",
       " 'or the other hand the bright',\n",
       " 'how to feed beef cattle .',\n",
       " 'one of the united states .',\n",
       " 'in the world . the first']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list = [\" \".join(sent) for sent in sentence_list]\n",
    "sentence_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('generated_text_brown.pickle', 'wb') as f:\n",
    "    pickle.dump(sentence_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['however the first time in the',\n",
       " 'moreover the centralization of government .',\n",
       " 'at the same time . the',\n",
       " 'from the fact that the united',\n",
       " 'his own . he was a']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_gen = open(\"generated_text_brown.pickle\",\"rb\")\n",
    "gen_text_brown = pickle.load(pickle_gen)\n",
    "gen_text_brown[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Probabilistic Model testing on Generated and Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. On Generated text (generated Brown and Guttenberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the generated data to used as input for models \n",
    "\n",
    "gen_text_gut = pickle.load(open(\"generated_text_guten.pickle\",\"rb\"))\n",
    "gen_text_brown = pickle.load(open(\"generated_text_brown.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus(sentence_list):\n",
    "    corp = sentence_list[0].split()\n",
    "    for i in tqdm(range(1,len(sentence_list))):\n",
    "        corp = corp + sentence_list[i].split()\n",
    "    return corp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcb6ec8993744b69fe4ae64f7de9e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148999.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e65bdb439d451ab5e1bc4844aa618b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148999.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#tokenizing all text instead instead of last 1000 sentences which will be used to test\n",
    "gutten_corpus_train = generate_corpus(gen_text_gut[:-1000])\n",
    "brown_corpus_train = generate_corpus(gen_text_brown[:-1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the train data \n",
    "with open('generated_text_guten_joined.pickle', 'wb') as f:\n",
    "    pickle.dump(gutten_corpus_train, f)\n",
    "with open('generated_text_brown_joined.pickle', 'wb') as f:\n",
    "    pickle.dump(brown_corpus_train, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing generated **Brown** and **Guttenberg** corpus using 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_g = autoComplete()\n",
    "ac_g.pre_process_corpus(gutten_corpus_train, n_gram_len=3, top_n=100, show_status=False)\n",
    "\n",
    "ac_b = autoComplete()\n",
    "ac_b.pre_process_corpus(gutten_corpus_train, n_gram_len=3, top_n=100, show_status=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gutten = gen_text_gut[-1000:]\n",
    "test_brown  = gen_text_brown[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the first two tokens of test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_tokens_gutten = [item.split()[:2] for item in test_gutten]\n",
    "start_tokens_brown = [item.split()[:2] for item in test_brown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the sake of his own ['for', 'the']\n",
      "perhaps the most important of all ['perhaps', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(test_gutten[0], start_tokens_gutten[0])\n",
    "print(test_brown[0], start_tokens_brown[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating sentences using first two tokens of original sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec04c3fc9774a6d98709fc671c6fde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating sentences by providing the first two tokens from the original sentence\n",
    "\n",
    "gen_test_gutten = []\n",
    "gen_test_brown  = []\n",
    "\n",
    "# generating limited data\n",
    "max_len = 4\n",
    "for i in tqdm(range(1000)):\n",
    "    out_g = ac_g.finish_sentence(start_tokens_gutten[i], 3,  max_len=max_len, deterministic=True, stop_at_punc=False)\n",
    "    gen_test_gutten.append(out_g)\n",
    "    out_b = ac_b.finish_sentence(start_tokens_brown[i], 3,  max_len=max_len, deterministic=True, stop_at_punc=False)\n",
    "    gen_test_brown.append(out_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guttenberg :\n",
      "Original sentence : for the sake of his own\n",
      "Generated sentence : for the sake of his own\n",
      "\n",
      "Brown :\n",
      "Original sentence : it is not a single stage\n",
      "Generated sentence : it is not to be sure\n"
     ]
    }
   ],
   "source": [
    "print(\"Guttenberg :\")\n",
    "print(f\"Original sentence : {test_gutten[0]}\")\n",
    "print(f\"Generated sentence : {' '.join(gen_test_gutten[0])}\")\n",
    "\n",
    "print(\"\\nBrown :\")\n",
    "print(f\"Original sentence : {test_brown[2]}\")\n",
    "print(f\"Generated sentence : {' '.join(gen_test_brown[2])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to pickle to save resutls\n",
    "with open('../data/test_orig_gutten.pickle', 'wb') as f:\n",
    "    pickle.dump(test_gutten, f)\n",
    "with open('../data/test_orig_brown.pickle', 'wb') as f:\n",
    "    pickle.dump(test_brown, f)\n",
    "\n",
    "with open('../data/test_gen_gutten.pickle', 'wb') as f:\n",
    "    pickle.dump(gen_test_gutten, f)\n",
    "with open('../data/test_gen_brown.pickle', 'wb') as f:\n",
    "    pickle.dump(gen_test_brown, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the results for **Guttenberg** and **Brown**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Brown:\n",
      "\n",
      "Original  : about it . i am sure\n",
      "Generated : about it . i am sure\n",
      "\n",
      "Original  : as she had been in the\n",
      "Generated : as she had been in the\n",
      "\n",
      "Original  : certainly not . i am sure\n",
      "Generated : certainly not . i am sure\n",
      "\n",
      "Original  : indeed ! and i am sure\n",
      "Generated : indeed ! and i am sure\n",
      "\n",
      "Original  : that she had been in the\n",
      "Generated : that she had been in the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_test_gutten = pickle.load(open(\"../data/test_gen_gutten.pickle\",\"rb\"))\n",
    "test_gutten = pickle.load(open(\"../data/test_orig_gutten.pickle\",\"rb\"))\n",
    "gen_test_gutten = [\" \".join(item) for item in gen_test_gutten]\n",
    "\n",
    "\n",
    "sample_ = np.random.choice(np.arange(len(test_brown)),5, replace=False)\n",
    "print(\"\\nResults for Brown:\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"Original  : {test_gutten[int(sample_[i])]}\")\n",
    "    print(f\"Generated : {gen_test_gutten[int(sample_[i])]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Brown:\n",
      "\n",
      "Original  : sometimes he would have been a\n",
      "Generated : sometimes he was not in the\n",
      "\n",
      "Original  : with the same time . the\n",
      "Generated : with the same time . lucy\n",
      "\n",
      "Original  : all the way to the editor\n",
      "Generated : all the world . elinor was\n",
      "\n",
      "Original  : those who have been a good\n",
      "Generated : those who had not been able\n",
      "\n",
      "Original  : in the world . the first\n",
      "Generated : in the world . elinor was\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_brown = pickle.load(open(\"../data/test_orig_brown.pickle\",\"rb\"))\n",
    "gen_test_brown = pickle.load(open(\"../data/test_gen_brown.pickle\",\"rb\"))\n",
    "gen_test_brown = [\" \".join(item) for item in gen_test_brown]\n",
    "\n",
    "\n",
    "sample_ = np.random.choice(np.arange(len(test_brown)),5, replace=False)\n",
    "print(\"\\nResults for Brown:\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"Original  : {test_brown[int(sample_[i])]}\")\n",
    "    print(f\"Generated : {gen_test_brown[int(sample_[i])]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## 2. On Real data (IMDB Movie plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for real data using IMDB Movie plots\n",
    "pickle_in = open(\"../data/plots_text.pickle\",\"rb\")\n",
    "movie_plots = pickle.load(pickle_in)\n",
    "\n",
    "# count of movie plot summaries\n",
    "len(movie_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the data step 1\n",
    "plot_corpus = [re.sub(\"[^a-z'\\. ]\", \"\", i) for i in movie_plots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences found : 8134\n"
     ]
    }
   ],
   "source": [
    "#function to extract sentence from the corpus for test cases\n",
    "sentences_plot = []\n",
    "for i in range(len(plot_corpus)):\n",
    "    sents = (re.split(pattern, plot_corpus[i]))\n",
    "    sentences_plot.extend(sents)\n",
    "print(f\"Sentences found : {len(sentences_plot)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the data step 2\n",
    "#Removing the fullstop and merging all sentences and creating tokens\n",
    "plot_corpus = [re.sub(\"[^a-z' ]\", \"\", i) for i in plot_corpus]\n",
    "plot_corpus = \" \".join(plot_corpus).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.choice(np.arange(len(sentences_plot)),1000, replace=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she is also convinced bram got the hots for kevin as he visits the bistro quite often and can't keep his eyes of bram. ['she', 'is']\n"
     ]
    }
   ],
   "source": [
    "subset_sentences = [sentences_plot[idx] for idx in rand_idx]\n",
    "subset_start = [item.split()[:2] for item in subset_sentences]\n",
    "print(subset_sentences[0], subset_start[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing all the Movie plots dataset to create 3-gram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the corpus\n",
    "ac_m = autoComplete()\n",
    "ac_m.pre_process_corpus(plot_corpus, n_gram_len=3, top_n=100, show_status=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating sentences using first two tokens of randomly selected 1000 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4de00fb7a664192938dcb582d35febd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating test sentences by providing two input tokens\n",
    "\n",
    "gen_test_plot = []\n",
    "gen_test_plot_unresitricted = []\n",
    "max_len = 4\n",
    "for i in tqdm(range(1000)):\n",
    "    gen_plot = ac_m.finish_sentence(subset_start[i], 3,  max_len=max_len, deterministic=True, stop_at_punc=False)\n",
    "    gen_test_plot.append(gen_plot)\n",
    "    \n",
    "    gen_plot = ac_m.finish_sentence(subset_start[i], 3,  max_len=20, deterministic=True, stop_at_punc=True)\n",
    "    gen_test_plot_unresitricted.append(gen_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Plot contains 1000 generated text. \n",
      "Sample :\n",
      "Original sentence : devoe then leads a special forces unit to stop them.\n",
      "Generated sentence (restricted): devoe then leads a commando raid\n",
      "Generated sentence (un-restricted): devoe then leads a commando raid depicted was intended to be a good thing after a few days later they disappear and\n"
     ]
    }
   ],
   "source": [
    "sample_n = int(np.random.choice(np.arange(1000),1))\n",
    "print(f\"\\nPlot contains {len(subset_start)} generated text. \\nSample :\")\n",
    "print(f\"Original sentence : {subset_sentences[sample_n]}\")\n",
    "print(f\"Generated sentence (restricted): {' '.join(gen_test_plot[sample_n])}\")\n",
    "print(f\"Generated sentence (un-restricted): {' '.join(gen_test_plot_unresitricted[sample_n])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/test_orig_plot.pickle', 'wb') as f:\n",
    "    pickle.dump(subset_sentences, f)\n",
    "\n",
    "with open('../data/test_gen_plot_restricted.pickle', 'wb') as f:\n",
    "    pickle.dump(gen_test_plot, f)\n",
    "    \n",
    "with open('../data/test_gen_plot_unrestricted.pickle', 'wb') as f:\n",
    "    pickle.dump(gen_test_plot_unresitricted, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the results for Movie plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Movie plot:\n",
      "\n",
      "Original  : meanwhile hsiao in a grave robbery attempt accidentally awakens a female corpse  who eventually turns out to be the marshal's  wife.\n",
      "Generated : meanwhile hsiao in a car accident all of the film ends with a large sum of money he discovers that the man\n",
      "\n",
      "Original  : this leads to a running joke in the torture chamber as henry keeps changing his mind about the confession due to political necessities requiring multiple changes and retractions of the original confession.\n",
      "Generated : this leads to a nearby bus station and also a bit awkwardly jrgen stalls the negotiations relating to deceased crew members as\n",
      "\n",
      "Original  : it sensitively portrays the struggles of a father whose main priority in life is the wellbeing of his children and who is determined to see his children grow up to become decent successful people.\n",
      "Generated : it sensitively portrays the conservative pan indian socio cultural life where he is not the only one who was the only one\n",
      "\n",
      "Original  : ibrahim is a year old muslim born in belgium.\n",
      "Generated : ibrahim is a film about a bumbling searchlight unit during world war ii developing the idea of destroying the helicopter blair has\n",
      "\n",
      "Original  : the trio escape into the wilderness after accidentally revealing the location of no.\n",
      "Generated : the trio escape into the house and after a few days later they disappear and take them to the house and after\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_plot = pickle.load(open('../data/test_orig_plot.pickle','rb'))\n",
    "gen_test_plot = pickle.load(open(\"../data/test_gen_plot_unrestricted.pickle\",\"rb\"))\n",
    "gen_test_plot = [\" \".join(item) for item in gen_test_plot]\n",
    "\n",
    "\n",
    "sample_ = np.random.choice(np.arange(len(test_brown)),5, replace=False)\n",
    "print(\"\\nResults for Movie plot:\\n\")\n",
    "for i in range(5):\n",
    "    print(f\"Original  : {test_plot[int(sample_[i])]}\")\n",
    "    print(f\"Generated : {gen_test_plot[int(sample_[i])]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
